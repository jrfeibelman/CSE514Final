{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, getopt\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('mode.chained_assignment', 'raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Helper Functions\n",
    "\"\"\"\n",
    "\n",
    "def getResults(perf, keys):\n",
    "    results = {}\n",
    "    for key in keys:\n",
    "        data = []\n",
    "        for p in perf[key]:\n",
    "            sensitivity = p['1']['recall']\n",
    "            specificity = p['-1']['recall']\n",
    "            accuracy = p['accuracy']\n",
    "            precision = p['macro avg']['precision']\n",
    "            recall = p['macro avg']['recall']\n",
    "            f1 = p['macro avg']['f1-score']\n",
    "            json = {'Sensitivity':sensitivity, 'Specificity':specificity, 'Accuracy':accuracy, 'Precision':precision, 'Recall':recall, 'F1':f1}\n",
    "            data.append(json)\n",
    "        results[key] = pd.DataFrame(data).mean()    \n",
    "    return pd.DataFrame(results).T\n",
    "\n",
    "def split_xy(df):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        df : dataframe\n",
    "    return:\n",
    "        tuple\n",
    "            0 - dataframe of data w\n",
    "            1 - ser\n",
    "    \"\"\"\n",
    "    y = df['Class']\n",
    "    x = df.drop('Class',axis=1)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data Collection\n",
    "\"\"\"\n",
    "colnames = ['Sample code number','Clump Thickness','Uniformity of Cell Size','Uniformity of Cell Shape','Marginal Adhesion','Single Epithelial Cell Size','Bare Nuclei','Bland Chromatin','Normal Nucleoli','Mitoses','Class']        \n",
    "classes = {1 : 'benign', -1 : 'malignant'}\n",
    "# All columns have values b/w 1-10 except for first (id) and last (class)\n",
    "data = pd.read_csv('breast-cancer-wisconsin.data', names=colnames)\n",
    "data.loc[(data['Class'] == 2),'Class'] = 1\n",
    "data.loc[(data['Class'] == 4),'Class'] = -1\n",
    "# ADJUST FOR MISISNG DATA '?'\n",
    "data = data.replace('?', np.nan)\n",
    "\n",
    "test_data = data.sample(frac=.1)\n",
    "pre_train_data = data.drop(test_data.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knnMethod(train_x, train_y, test_x, test_y, imputer, n_neighbors=1, p=1):\n",
    "    xTri, xTei = imputer.fit_transform(train_x), imputer.fit_transform(test_x)\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors, p=p) # p-l1 vs l2 distance\n",
    "    knn.fit(xTri, train_y)\n",
    "    preds_knn = knn.predict(xTei)\n",
    "    perf = classification_report(test_y, preds_knn,output_dict=True)\n",
    "    print(\"1-kNN %f\" % perf['macro avg']['f1-score'])\n",
    "    return perf\n",
    "    \n",
    "def decisionTree(train_x, train_y, test_x, test_y, imputer):\n",
    "    xTri, xTei = imputer.fit_transform(train_x), imputer.fit_transform(test_x)\n",
    "    dt = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "    dt.fit(xTri, train_y)\n",
    "    preds_dt = dt.predict(xTei)\n",
    "    perf = classification_report(test_y, preds_dt,output_dict=True)\n",
    "    print(\"Decision Tree %f\" % perf['macro avg']['f1-score'])\n",
    "    return perf\n",
    "\n",
    "def randomForest(train_x, train_y, test_x, test_y, imputer, n_estimators=100):\n",
    "    xTri, xTei = imputer.fit_transform(train_x), imputer.fit_transform(test_x)\n",
    "    rf = RandomForestClassifier(criterion=\"gini\", n_estimators=100)\n",
    "    rf.fit(xTri, train_y)\n",
    "    preds_rf = rf.predict(xTei)\n",
    "    perf = classification_report(test_y, preds_rf,output_dict=True)\n",
    "    print(\"Random Forest %f\" % perf['macro avg']['f1-score'])\n",
    "    return perf\n",
    "\n",
    "def polynomialSVC(train_x, train_y, test_x, test_y, imputer):\n",
    "    xTri, xTei = imputer.fit_transform(train_x), imputer.fit_transform(test_x)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(xTri)\n",
    "    xTrs, xTes = scaler.transform(xTri), scaler.transform(xTei)\n",
    "    svm_3 = svm.SVC(kernel='poly', degree=3, gamma='scale', coef0=131, C=12, tol=.0001)\n",
    "    svm_3.fit(xTrs, train_y)\n",
    "    preds_svm3 = svm_3.predict(xTes)\n",
    "    perf = classification_report(test_y, preds_svm3,output_dict=True, zero_division=True)\n",
    "    print(\"[Polynomial^3] SVM %f\" % perf['macro avg']['f1-score'])\n",
    "    return perf\n",
    "    \n",
    "def gaussianSVC(train_x, train_y, test_x, test_y, imputer):\n",
    "    xTri, xTei = imputer.fit_transform(train_x), imputer.fit_transform(test_x)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(xTri)\n",
    "    xTrs, xTes = scaler.transform(xTri), scaler.transform(xTei)\n",
    "    svm_g = svm.SVC(kernel='rbf', gamma='auto', C=12, tol=.0001)\n",
    "    svm_g.fit(xTrs, train_y)\n",
    "    preds_svmg = svm_g.predict(xTes)\n",
    "    perf = classification_report(test_y, preds_svmg,output_dict=True, zero_division=True)\n",
    "    print(\"[Gaussian] SVM %f\" % perf['macro avg']['f1-score'])\n",
    "    return perf\n",
    "    \n",
    "def sigmoidNN(train_x, train_y, test_x, test_y, imputer):\n",
    "    xTri, xTei = imputer.fit_transform(train_x), imputer.fit_transform(test_x)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(xTri)\n",
    "    xTrnn, xTenn = scaler.transform(xTri), scaler.transform(xTei)\n",
    "    mlp_sig = MLPClassifier(hidden_layer_sizes=(10,10,10), activation='logistic', max_iter=1500, alpha=.00001, tol=.0001, beta_1=.8, beta_2=.95, epsilon=.00000000001)\n",
    "    mlp_sig.fit(xTrnn, train_y) # train_y.values.ravel() converts Series -> np.ndarray\n",
    "    preds_nn_sig = mlp_sig.predict(xTenn)\n",
    "    perf = classification_report(test_y, preds_nn_sig,output_dict=True,zero_division=True)\n",
    "    print(\"Sigmoid NN %f\" % perf['macro avg']['f1-score'])\n",
    "    return perf\n",
    "    \n",
    "def reluNN(train_x, train_y, test_x, test_y, imputer):\n",
    "    xTri, xTei = imputer.fit_transform(train_x), imputer.fit_transform(test_x)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(xTri)\n",
    "    xTrnn, xTenn = scaler.transform(xTri), scaler.transform(xTei)\n",
    "    mlp_relu = MLPClassifier(hidden_layer_sizes=(10,10,10), activation='relu', max_iter=1500, alpha=.00001, tol=.001, beta_1=.8, beta_2=.95, epsilon=.00000000001)\n",
    "    mlp_relu.fit(xTrnn, train_y) # train_y.values.ravel() converts Series -> np.ndarray\n",
    "    preds_nn_relu = mlp_relu.predict(xTenn)\n",
    "    perf = classification_report(test_y, preds_nn_relu, output_dict=True, zero_division=True)\n",
    "    print(\"Relu NN %f\" % perf['macro avg']['f1-score'])\n",
    "    return perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-kNN 0.656140\n",
      "Decision Tree 0.969854\n",
      "Random Forest 0.984819\n",
      "[Polynomial^3] SVM 0.936594\n",
      "[Gaussian] SVM 0.906667\n",
      "Sigmoid NN 0.984819\n",
      "Relu NN 0.984819\n",
      "1-kNN 0.619565\n",
      "Decision Tree 0.969854\n",
      "Random Forest 1.000000\n",
      "[Polynomial^3] SVM 0.906667\n",
      "[Gaussian] SVM 0.909561\n",
      "Sigmoid NN 1.000000\n",
      "Relu NN 0.969854\n",
      "1-kNN 0.643848\n",
      "Decision Tree 0.984819\n",
      "Random Forest 1.000000\n",
      "[Polynomial^3] SVM 0.921507\n",
      "[Gaussian] SVM 0.906667\n",
      "Sigmoid NN 0.969854\n",
      "Relu NN 0.984819\n",
      "1-kNN 0.682971\n",
      "Decision Tree 0.969854\n",
      "Random Forest 1.000000\n",
      "[Polynomial^3] SVM 0.904891\n",
      "[Gaussian] SVM 0.893732\n",
      "Sigmoid NN 1.000000\n",
      "Relu NN 1.000000\n",
      "1-kNN 0.643848\n",
      "Decision Tree 1.000000\n",
      "Random Forest 1.000000\n",
      "[Polynomial^3] SVM 0.921507\n",
      "[Gaussian] SVM 0.922891\n",
      "Sigmoid NN 1.000000\n",
      "Relu NN 1.000000\n",
      "1-kNN 0.580436\n",
      "Decision Tree 0.954457\n",
      "Random Forest 1.000000\n",
      "[Polynomial^3] SVM 0.953734\n",
      "[Gaussian] SVM 0.922891\n",
      "Sigmoid NN 1.000000\n",
      "Relu NN 0.969854\n",
      "1-kNN 0.635417\n",
      "Decision Tree 0.969406\n",
      "Random Forest 1.000000\n",
      "[Polynomial^3] SVM 0.906667\n",
      "[Gaussian] SVM 0.875556\n",
      "Sigmoid NN 1.000000\n",
      "Relu NN 0.955080\n",
      "1-kNN 0.688889\n",
      "Decision Tree 0.984819\n",
      "Random Forest 1.000000\n",
      "[Polynomial^3] SVM 0.904891\n",
      "[Gaussian] SVM 0.938811\n",
      "Sigmoid NN 0.984819\n",
      "Relu NN 1.000000\n",
      "1-kNN 0.623392\n",
      "Decision Tree 0.984819\n",
      "Random Forest 1.000000\n",
      "[Polynomial^3] SVM 0.904891\n",
      "[Gaussian] SVM 0.922891\n",
      "Sigmoid NN 1.000000\n",
      "Relu NN 0.984819\n",
      "1-kNN 0.635417\n",
      "Decision Tree 0.968889\n",
      "Random Forest 1.000000\n",
      "[Polynomial^3] SVM 0.887898\n",
      "[Gaussian] SVM 0.908217\n",
      "Sigmoid NN 1.000000\n",
      "Relu NN 0.984819\n",
      "FINISHED\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.660266</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.640992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.972727</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.977143</td>\n",
       "      <td>0.973630</td>\n",
       "      <td>0.978671</td>\n",
       "      <td>0.975677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.997727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998571</td>\n",
       "      <td>0.998148</td>\n",
       "      <td>0.998864</td>\n",
       "      <td>0.998482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svmp</th>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.834615</td>\n",
       "      <td>0.922857</td>\n",
       "      <td>0.930777</td>\n",
       "      <td>0.904808</td>\n",
       "      <td>0.914925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svmg</th>\n",
       "      <td>0.940909</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.917143</td>\n",
       "      <td>0.913569</td>\n",
       "      <td>0.908916</td>\n",
       "      <td>0.910788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nnsig</th>\n",
       "      <td>0.990909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994286</td>\n",
       "      <td>0.992725</td>\n",
       "      <td>0.995455</td>\n",
       "      <td>0.993949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nnrelu</th>\n",
       "      <td>0.975000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984286</td>\n",
       "      <td>0.980277</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.983406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sensitivity  Specificity  Accuracy  Precision    Recall        F1\n",
       "knn        0.825000     0.450000  0.685714   0.660266  0.637500  0.640992\n",
       "dt         0.972727     0.984615  0.977143   0.973630  0.978671  0.975677\n",
       "rf         0.997727     1.000000  0.998571   0.998148  0.998864  0.998482\n",
       "svmp       0.975000     0.834615  0.922857   0.930777  0.904808  0.914925\n",
       "svmg       0.940909     0.876923  0.917143   0.913569  0.908916  0.910788\n",
       "nnsig      0.990909     1.000000  0.994286   0.992725  0.995455  0.993949\n",
       "nnrelu     0.975000     1.000000  0.984286   0.980277  0.987500  0.983406"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cross Validation\n",
    "https://machinelearningmastery.com/repeated-k-fold-cross-validation-with-python/\n",
    "\"\"\"\n",
    "cv_datasets = []\n",
    "imputers = [KNNImputer(n_neighbors=1)]\n",
    "keys = ['knn', 'dt', 'rf', 'svmp', 'svmg', 'nnsig', 'nnrelu']\n",
    "perf = {key:[] for key in keys}\n",
    "for train_idx,valid_idx in KFold(n_splits=10, random_state=1, shuffle=True).split(pre_train_data):\n",
    "    train_data = pre_train_data.iloc[train_idx]\n",
    "    valid_data = pre_train_data.iloc[valid_idx]\n",
    "    cv_datasets.append((train_data,valid_data))\n",
    "    train_x, train_y = split_xy(train_data)\n",
    "    valid_x, valid_y = split_xy(valid_data)\n",
    "    test_x, test_y = split_xy(test_data)\n",
    "    \n",
    "    perf['knn'].append(knnMethod(train_x, train_y, test_x, test_y, imputers[0]))\n",
    "    perf['dt'].append(decisionTree(train_x, train_y, test_x, test_y, imputers[0]))\n",
    "    perf['rf'].append(randomForest(train_x, train_y, test_x, test_y, imputers[0]))\n",
    "    perf['svmp'].append(polynomialSVC(train_x, train_y, test_x, test_y, imputers[0]))\n",
    "    perf['svmg'].append(gaussianSVC(train_x, train_y, test_x, test_y, imputers[0]))\n",
    "    perf['nnsig'].append(sigmoidNN(train_x, train_y, test_x, test_y, imputers[0]))\n",
    "    perf['nnrelu'].append(reluNN(train_x, train_y, test_x, test_y, imputers[0]))\n",
    "results = getResults(perf,keys)\n",
    "print(\"FINISHED\")\n",
    "display(results)\n",
    "# DEBUG\n",
    "train = cv_datasets[0][0]\n",
    "train_x, train_y = split_xy(train)\n",
    "valid = cv_datasets[0][1]\n",
    "valid_x, valid_y = split_xy(valid)\n",
    "test_x, test_y = split_xy(test_data)\n",
    "imputer = KNNImputer(n_neighbors=1)\n",
    "train_x = imputer.fit_transform(train_x)\n",
    "test_x = imputer.fit_transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n- work with output results perf, score --> get fmeasure, sensitivity, recall, ROC, accuracy, etc\\n- SVM ISSUES:\\n    - Sometimes infinite look\\n    - Experiment with soft margin\\n    \\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "- work with output results perf, score --> get fmeasure, sensitivity, recall, ROC, accuracy, etc\n",
    "- SVM ISSUES:\n",
    "    - Sometimes infinite look\n",
    "    - Experiment with soft margin\n",
    "    \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Grid Search\n",
    "\"\"\"\n",
    "param_grid_knn = {'p':[1,2], 'n_neighbors':[1,2,3,4,5]}\n",
    "param_grid_rf = {'criterion': ['gini'], 'n_estimators': [1, 5, 10, 50, 100, 500, 1000]}\n",
    "\n",
    "param_grid_svm = [\n",
    "    {'kernel':['poly'],'degree':[2,3,4,5], 'gamma':['scale'], 'coef0':[.01,.1,1,5,10,20,30,50,75,100,125,150,175,200], 'C':[.1,1,10,25,50,75,100,125,150,175,200], 'tol':[1e-1,1e-2,1e-3,1e-4,1e-5,1e-6,1e-7,1e-8]},\n",
    "    {'kernel':['rbf'],'gamma':['auto'],'C':[.1,1,10,25,50,75,100,125,150,175,200], 'tol':[1e-1,1e-2,1e-3,1e-4,1e-5,1e-6,1e-7,1e-8]}\n",
    "]                                \n",
    "\n",
    "param_grid_nn =[\n",
    "    {'hidden_layer_sizes':[(3,3,3),(5,5,5),(10,10,10)],'activation':[\"logistic\"],'max_iter':[100,500,1000,1500,2000,3000],'alpha':[.1,.01,.001,.0001,.00001,.000001],'tol':[1e-2,1e-3,1e-4,1e-5,1e-6],'beta_1':[.01,.1,.2,.3,.4,.5,.6,.7,.8,.9],'beta_2':[.015,.15,.25,.35,.45,.55,.65,.75,.85,.95],'epsilon':[1e-4,1e-5,1e-6,1e-7,1e-8,1e-9,1e-10]},\n",
    "    {'hidden_layer_sizes':[(3,3,3),(5,5,5),(10,10,10)],'activation':[\"relu\"],    'max_iter':[100,500,1000,1500,2000,3000],'alpha':[.1,.01,.001,.0001,.00001,.000001],'tol':[1e-2,1e-3,1e-4,1e-5,1e-6],'beta_1':[.01,.1,.2,.3,.4,.5,.6,.7,.8,.9],'beta_2':[.015,.15,.25,.35,.45,.55,.65,.75,.85,.95],'epsilon':[1e-4,1e-5,1e-6,1e-7,1e-8,1e-9,1e-10]}\n",
    "]\n",
    "\n",
    "\n",
    "# max_iter=1500, alpha=.00001, tol=.0001, beta_1=.8, beta_2=.95, epsilon=.00000000001\n",
    "\n",
    "\n",
    "clf_k = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=param_grid_knn, n_jobs=-1, cv=5)\n",
    "clf_k.fit(train_x, train_y)\n",
    "print(clf_k.best_params_)\n",
    "\n",
    "# NOT CONSTANT \n",
    "clf_rf = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid_rf, n_jobs=-1, cv=5)\n",
    "clf_rf.fit(train_x, train_y)\n",
    "print(clf_rf.best_params_)\n",
    "\n",
    "clf_svm = GridSearchCV(estimator=svm.SVC(), param_grid=param_grid_svm, n_jobs=-1, cv=5)\n",
    "clf_svm.fit(train_x, train_y)\n",
    "print(clf_svm.best_params_)\n",
    "\n",
    "# CURSE OF DIM : takes too long too run\n",
    "# clf_nn = GridSearchCV(estimator=MLPClassifier(), param_grid=param_grid_nn, n_jobs=-1)\n",
    "# clf_nn.fit(train_x_knn, train_y)\n",
    "\n",
    "# print(clf_k.best_params_)\n",
    "# print(clf_rf.best_params_)\n",
    "# print(clf_nn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = clf_k.predict(test_x)\n",
    "score = clf_k.score(test_x,test_y)\n",
    "print(score)\n",
    "perf = classification_report(test_y, p,output_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Try computing confusion matrix\n",
    "# confusion_matrix(y_pred, y_val)\n",
    "# accuracy(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO:\n",
    "    - Cross Validation --> over all 10 data sets --> and validation\n",
    "    - Grid search for correct parameters\n",
    "        --> SVM Help?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    opts, args = getopt.getopt(sys.argv[1:],\"d:a:f\")\n",
    "    degree = 1\n",
    "    for a, b in opts:\n",
    "        if a == '-d':\n",
    "            degree = b\n",
    "        elif a == '-a':\n",
    "            degree = -1\n",
    "        else:\n",
    "            print(\"Usage: %s <-d degree#> <-a>\" % sys.argv[0])\n",
    "    \n",
    "    print(degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
